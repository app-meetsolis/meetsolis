# Story 2.2: Essential Video Controls and Audio Management

## Status
Draft

## Story

**As a** meeting participant,
**I want** intuitive controls for mute, video, and audio settings,
**so that** I can quickly manage my presence during client calls.

## Acceptance Criteria

1. Prominent mute/unmute toggle with visual and audio feedback
2. Video on/off toggle with privacy-first defaults
3. AI-powered noise suppression integration via WebRTC
4. Audio source selection (microphone) with pre-call testing
5. Video source selection (camera) with quality preview
6. Speaker/output device selection and volume controls
7. Push-to-talk functionality with keyboard shortcuts
8. Auto-mute on join option with host override capabilities
9. Visual indicators for muted participants and speaking detection
10. Keyboard shortcuts (React-Hotkeys) for all controls (M for mute, V for video)

## Dependencies

**Required:**
- **Story 2.1** (WebRTC Infrastructure) - Must be complete for video stream management

## Tasks / Subtasks

- [ ] **Control Bar Component** (AC: 1, 2, 10)
  - [ ] Create `ControlBar.tsx` component in `src/components/meeting/`
  - [ ] Design bottom control bar layout with centered controls
  - [ ] Implement mute/unmute button with microphone icon
  - [ ] Implement video on/off button with camera icon
  - [ ] Add visual feedback (red slash for muted/off states)
  - [ ] Implement keyboard shortcuts using react-hotkeys-hook
  - [ ] Add tooltips for all control buttons
  - [ ] Ensure WCAG 2.1 AA compliance (keyboard nav, ARIA labels)
  - [ ] Write component tests using @testing-library/react

- [ ] **Audio Controls Hook** (AC: 1, 3, 9)
  - [ ] Create `useAudioControls` hook in `src/hooks/meeting/`
  - [ ] Implement mute/unmute functionality on MediaStreamTrack
  - [ ] Add audio feedback (beep) on mute/unmute actions
  - [ ] Integrate WebRTC noise suppression API
  - [ ] Implement speaking detection using AudioContext analyser
  - [ ] Add visual speaking indicator (green border on video tile)
  - [ ] Handle audio track cleanup on component unmount
  - [ ] Write unit tests for audio control logic

- [ ] **Video Controls Hook** (AC: 2)
  - [ ] Create `useVideoControls` hook in `src/hooks/meeting/`
  - [ ] Implement video on/off functionality on MediaStreamTrack
  - [ ] Add privacy screen when video is off (avatar/initials)
  - [ ] Handle video track enable/disable transitions smoothly
  - [ ] Implement default video-off on join (privacy-first)
  - [ ] Add video preview before enabling
  - [ ] Write unit tests for video control logic

- [ ] **Device Settings Panel** (AC: 4, 5, 6)
  - [ ] Create `DeviceSettingsPanel` component in `src/components/meeting/`
  - [ ] Implement microphone device selection dropdown
  - [ ] Add microphone test with audio level meter
  - [ ] Implement camera device selection dropdown
  - [ ] Add camera preview for selected device
  - [ ] Implement speaker/output device selection
  - [ ] Add speaker test with audio playback
  - [ ] Add volume slider for output control
  - [ ] Save device preferences to localStorage
  - [ ] Write component tests for device selection

- [ ] **Push-to-Talk Feature** (AC: 7, 10)
  - [ ] Implement push-to-talk mode using Space bar
  - [ ] Add visual indicator when in push-to-talk mode
  - [ ] Handle Space key press/release for audio control
  - [ ] Add toggle to enable/disable push-to-talk mode
  - [ ] Prevent Space key conflicts with other UI elements
  - [ ] Add push-to-talk instructions in UI
  - [ ] Write tests for keyboard event handling

- [ ] **Auto-Mute & Host Controls** (AC: 8)
  - [ ] Implement auto-mute on join setting in user preferences
  - [ ] Create API endpoint `/api/meetings/[id]/participants/[userId]/mute` (PUT)
  - [ ] Add host ability to mute individual participants
  - [ ] Implement "mute all" functionality for hosts
  - [ ] Add participant notification when muted by host
  - [ ] Update participant state in database (is_muted field)
  - [ ] Sync mute state via Supabase Realtime
  - [ ] Write API endpoint tests

- [ ] **Keyboard Shortcuts System** (AC: 10)
  - [ ] Install and configure react-hotkeys-hook ^4.4.1
  - [ ] Implement global keyboard shortcut listener
  - [ ] Add M key for mute/unmute toggle
  - [ ] Add V key for video on/off toggle
  - [ ] Add Space key for push-to-talk
  - [ ] Create keyboard shortcuts help modal (? key)
  - [ ] Display active shortcuts overlay
  - [ ] Prevent shortcuts when typing in text fields
  - [ ] Add ARIA live region for screen reader announcements
  - [ ] Write tests for keyboard shortcut behavior

- [ ] **Visual Feedback & Indicators** (AC: 1, 9)
  - [ ] Add muted icon overlay on participant video tiles
  - [ ] Implement speaking indicator (green border animation)
  - [ ] Add audio level visualization in control bar
  - [ ] Create toast notifications for control state changes
  - [ ] Add haptic feedback for mobile devices
  - [ ] Implement smooth transitions for all state changes
  - [ ] Write visual regression tests

- [ ] **Noise Suppression Integration** (AC: 3)
  - [ ] Research WebRTC noise suppression API availability
  - [ ] Implement noise suppression toggle in device settings
  - [ ] Add browser compatibility checks for noise suppression
  - [ ] Provide fallback UI when not supported
  - [ ] Test noise suppression with various audio inputs
  - [ ] Add noise suppression status indicator
  - [ ] Write integration tests

- [ ] **State Management & Persistence** (AC: 1, 2, 8)
  - [ ] Create control state types in `packages/shared/types/`
  - [ ] Implement control state management with Context API
  - [ ] Sync control states across all participants via Realtime
  - [ ] Persist user preferences to localStorage
  - [ ] Update participant state in Supabase database
  - [ ] Handle state conflicts (local vs remote)
  - [ ] Write state management tests

## Dev Notes

### Dependencies

**Story 2.1 Context:**
- WebRTC infrastructure with `useMediaStream` hook
- Local MediaStream management
- Participant state tracking in database
- Supabase Realtime for signaling

This story builds on Story 2.1 by adding control mechanisms for the existing video/audio streams.

### Previous Story Insights

From **Story 2.1** (WebRTC Infrastructure):
- MediaStream and MediaStreamTrack APIs for audio/video control
- Supabase Realtime for participant state synchronization
- Component structure: `src/components/meeting/`
- State management with @tanstack/react-query
- WCAG 2.1 AA accessibility requirements

From **Story 1.9** (Security & Validation):
- Zod validation for API endpoints
- Rate limiting (100 req/min per user)
- CSRF protection via Clerk JWT
- Input sanitization with sanitize-html

### Technology Stack

[Source: architecture/tech-stack.md]

**Required Dependencies:**
- `react-hotkeys-hook` ^4.4.1 - Keyboard shortcut management
- `react-toastify` ^9.1.3 - Toast notifications for feedback
- `@tanstack/react-query` ^5.17.0 - State management
- `@supabase/realtime-js` ^2.9.3 - Real-time state sync

**Testing:**
- `Jest` ^29.7.0 - Unit tests
- `@testing-library/react` ^14.1.2 - Component tests
- `@testing-library/user-event` ^14.5.1 - User interaction tests

### MediaStream Track Control

[Source: WebRTC API Documentation]

**Audio Track Control:**
```typescript
// Mute/unmute audio
const audioTrack = localStream.getAudioTracks()[0];
audioTrack.enabled = false; // Mute
audioTrack.enabled = true;  // Unmute

// Apply noise suppression
const audioConstraints = {
  audio: {
    echoCancellation: true,
    noiseSuppression: true,
    autoGainControl: true
  }
};
```

**Video Track Control:**
```typescript
// Video on/off
const videoTrack = localStream.getVideoTracks()[0];
videoTrack.enabled = false; // Video off
videoTrack.enabled = true;  // Video on
```

**Speaking Detection:**
```typescript
// Use Web Audio API for speaking detection
const audioContext = new AudioContext();
const analyser = audioContext.createAnalyser();
const microphone = audioContext.createMediaStreamSource(localStream);
microphone.connect(analyser);

// Analyze audio levels
analyser.fftSize = 512;
const bufferLength = analyser.frequencyBinCount;
const dataArray = new Uint8Array(bufferLength);

function detectSpeaking() {
  analyser.getByteFrequencyData(dataArray);
  const average = dataArray.reduce((a, b) => a + b) / bufferLength;
  const isSpeaking = average > 30; // Threshold
  return isSpeaking;
}
```

### Component Architecture

[Source: architecture/frontend-architecture.md]

**Control Bar Layout:**
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                 â”‚
â”‚  [Settings]  [ðŸŽ¤ Mute]  [ðŸ“¹ Video]  [âš™ï¸ More]  â”‚
â”‚                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Component Files:**
- `src/components/meeting/ControlBar.tsx` - Main control bar
- `src/components/meeting/DeviceSettingsPanel.tsx` - Device selection modal
- `src/components/meeting/KeyboardShortcutsHelp.tsx` - Shortcuts help overlay

**Hook Files:**
- `src/hooks/meeting/useAudioControls.ts` - Audio control logic
- `src/hooks/meeting/useVideoControls.ts` - Video control logic
- `src/hooks/meeting/useKeyboardShortcuts.ts` - Keyboard shortcut logic
- `src/hooks/meeting/useSpeakingDetection.ts` - Speaking detection logic

### Database Schema Updates

[Source: architecture/database-schema.md]

**No new migrations required** - Story 2.1 already includes `participants` table with:
```sql
is_muted BOOLEAN DEFAULT TRUE,
is_video_off BOOLEAN DEFAULT FALSE,
```

**Update via API:** Use existing participant fields to track mute/video state.

### API Endpoints

**Required Endpoints:**

1. **PUT `/api/meetings/[id]/participants/[userId]/mute`**
   - Host mutes specific participant
   - Zod schema: `{ is_muted: boolean }`
   - Returns: Updated participant object

2. **PUT `/api/meetings/[id]/participants/mute-all`**
   - Host mutes all participants
   - Zod schema: `{ exclude_host: boolean }`
   - Returns: Array of updated participants

**Security:**
- Verify requester is host or co-host
- Clerk JWT authentication
- Rate limiting: 100 req/min per user
- Audit log for host actions

### Keyboard Shortcuts Implementation

[Source: react-hotkeys-hook documentation]

```typescript
import { useHotkeys } from 'react-hotkeys-hook';

export const useKeyboardShortcuts = (callbacks: ShortcutCallbacks) => {
  // M for mute/unmute
  useHotkeys('m', (e) => {
    e.preventDefault();
    callbacks.toggleMute();
  }, { enableOnFormTags: false });

  // V for video on/off
  useHotkeys('v', (e) => {
    e.preventDefault();
    callbacks.toggleVideo();
  }, { enableOnFormTags: false });

  // Space for push-to-talk
  useHotkeys('space', (e) => {
    e.preventDefault();
    callbacks.onPushToTalkStart();
  }, { keydown: true, enableOnFormTags: false });

  useHotkeys('space', (e) => {
    e.preventDefault();
    callbacks.onPushToTalkEnd();
  }, { keyup: true, enableOnFormTags: false });

  // ? for help
  useHotkeys('shift+/', () => {
    callbacks.openShortcutsHelp();
  }, { enableOnFormTags: false });
};
```

### State Management Pattern

[Source: architecture/frontend-architecture.md]

**Control State Structure:**
```typescript
interface ControlState {
  isAudioMuted: boolean;
  isVideoOff: boolean;
  isPushToTalkMode: boolean;
  isPushToTalkActive: boolean;
  selectedMicrophone: string | null;
  selectedCamera: string | null;
  selectedSpeaker: string | null;
  noiseSuppressionEnabled: boolean;
  autoMuteOnJoin: boolean;
}

// Context API for local control state
const ControlContext = React.createContext<ControlState | null>(null);

// React Query for participant state sync
const { data: participants } = useQuery({
  queryKey: ['meeting-participants', meetingId],
  queryFn: () => fetchParticipants(meetingId),
});
```

### Real-Time Synchronization

[Source: @supabase/realtime-js documentation]

**Sync participant states:**
```typescript
// Subscribe to participant changes
const channel = supabase
  .channel(`meeting:${meetingId}`)
  .on('postgres_changes', {
    event: 'UPDATE',
    schema: 'public',
    table: 'participants',
    filter: `meeting_id=eq.${meetingId}`
  }, (payload) => {
    // Update local participant state
    updateParticipant(payload.new);
  })
  .subscribe();
```

### Accessibility Requirements

[Source: architecture/frontend-architecture.md]

**WCAG 2.1 AA Compliance:**
- Keyboard navigation: Tab through controls, Enter/Space to activate
- ARIA labels: "Mute microphone", "Turn off video", etc.
- ARIA live regions: Announce state changes to screen readers
- Focus indicators: Visible 2px outline on focused controls
- Touch targets: Minimum 44x44px for mobile
- Color contrast: 4.5:1 for text and icons

**Keyboard Shortcuts:**
- Must work globally within meeting page
- Must not conflict with browser shortcuts
- Must be disabled when typing in input fields
- Must have help overlay (? key)

**Screen Reader Announcements:**
```typescript
// Example ARIA live region
<div role="status" aria-live="polite" className="sr-only">
  {isAudioMuted ? 'Microphone muted' : 'Microphone unmuted'}
</div>
```

### Visual Design Patterns

**Control Button States:**
- Default: Gray background, white icon
- Active: Blue background, white icon
- Muted/Off: Red background, white icon with slash
- Hover: Slight background darkening
- Focus: 2px blue outline

**Speaking Indicator:**
- Green border animation on video tile
- Pulsing effect at 1-2 Hz
- Visible even when participant is muted
- Different visual for self vs others

### User Preferences Storage

**localStorage Structure:**
```typescript
interface UserMeetingPreferences {
  autoMuteOnJoin: boolean;
  defaultVideoOff: boolean;
  preferredMicrophone: string | null;
  preferredCamera: string | null;
  preferredSpeaker: string | null;
  noiseSuppressionEnabled: boolean;
  pushToTalkMode: boolean;
}

// Save to localStorage
localStorage.setItem(
  'meetsolis_meeting_preferences',
  JSON.stringify(preferences)
);
```

### Testing Strategy

**Test File Locations:**
- Unit tests: `src/hooks/meeting/__tests__/`
- Component tests: `src/components/meeting/__tests__/`
- Integration tests: `src/app/api/meetings/__tests__/`

**Testing Standards:**

1. **Hook Tests (useAudioControls, useVideoControls):**
   - Mock MediaStreamTrack
   - Test mute/unmute logic
   - Test track enable/disable
   - Test cleanup on unmount
   - Coverage: >85%

2. **Component Tests (ControlBar, DeviceSettingsPanel):**
   - Test button click handlers
   - Test keyboard shortcuts
   - Test visual state changes
   - Test accessibility (ARIA labels, keyboard nav)
   - Use @testing-library/user-event for interactions

3. **API Endpoint Tests:**
   - Test host mute participant
   - Test mute-all functionality
   - Test authorization (only host/co-host)
   - Test rate limiting
   - Mock Supabase client

4. **Integration Tests:**
   - Test real-time state sync
   - Test control state persistence
   - Test device selection flow
   - Test keyboard shortcuts end-to-end

**Mock Strategies:**
```typescript
// Mock MediaStreamTrack
const mockAudioTrack = {
  enabled: true,
  kind: 'audio',
  stop: jest.fn(),
} as any as MediaStreamTrack;

// Mock Web Audio API
global.AudioContext = jest.fn().mockImplementation(() => ({
  createAnalyser: jest.fn(),
  createMediaStreamSource: jest.fn(),
}));

// Mock react-hotkeys-hook
jest.mock('react-hotkeys-hook', () => ({
  useHotkeys: jest.fn(),
}));
```

### Browser Compatibility

**Noise Suppression Support:**
- Chrome/Edge: âœ… Full support
- Firefox: âœ… Full support
- Safari: âš ï¸ Limited support (check feature detection)

**Feature Detection:**
```typescript
const supportsNoiseSuppression = () => {
  const constraints = { noiseSuppression: true };
  return navigator.mediaDevices
    .getSupportedConstraints()
    .noiseSuppression === true;
};
```

### Performance Considerations

- **Speaking Detection:** Run at 30 FPS max to avoid performance overhead
- **State Updates:** Debounce UI updates to avoid excessive re-renders
- **Real-Time Sync:** Batch participant updates to reduce database queries
- **Memory:** Clean up AudioContext on component unmount

### Known Constraints

1. **Push-to-Talk Limitation:** Space bar may conflict with form inputs - disabled in input fields
2. **Noise Suppression:** Safari has limited support - feature detection required
3. **Device Selection:** Some browsers don't support setSinkId for speaker selection
4. **Mobile:** Keyboard shortcuts not applicable - mobile UI patterns in Story 2.7

### Testing

**Required Testing Approach:**
- **Unit Tests:** Hook logic (audio/video controls, speaking detection)
- **Component Tests:** Control bar, device settings panel
- **Integration Tests:** Real-time state sync, API endpoints
- **E2E Tests:** Full control flow (mute, video, device selection)
- **Accessibility Tests:** Keyboard navigation, screen reader support

**Key Test Scenarios:**
1. User mutes/unmutes microphone via button
2. User toggles video on/off via button
3. User uses keyboard shortcuts (M, V, Space)
4. Host mutes individual participant
5. Host mutes all participants
6. User changes microphone/camera device
7. Speaking detection shows green border
8. Noise suppression toggle works
9. Control states sync across participants
10. Accessibility: keyboard navigation works

**Success Criteria:**
- All controls functional with visual feedback
- Keyboard shortcuts work as expected
- State persists across page refresh
- Real-time sync working (<1s latency)
- Accessibility tests pass (WCAG 2.1 AA)
- No memory leaks on component unmount

## Change Log

| Date | Version | Description | Author |
|------|---------|-------------|--------|
| 2025-11-13 | 1.0 | Initial story creation for video controls and audio management | Bob (Scrum Master) |

## Dev Agent Record

*This section will be populated by the development agent during implementation*

### Agent Model Used
*To be filled by dev agent*

### Debug Log References
*To be filled by dev agent*

### Completion Notes List
*To be filled by dev agent*

### File List
*To be filled by dev agent*

## QA Results

*Results from QA Agent review will be populated here after story completion*
